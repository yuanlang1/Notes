# 神经网络的学习(Neural Networks: Learning)

- [神经网络的学习(Neural Networks: Learning)](#神经网络的学习neural-networks-learning)
  - [1. Train a neural Network in Tensorflow](#1-train-a-neural-network-in-tensorflow)
  - [2. Model training steps](#2-model-training-steps)
    - [2.1 Create the model](#21-create-the-model)
    - [2.2 Loss and cost functions](#22-loss-and-cost-functions)
    - [2.3 Gradient descent](#23-gradient-descent)
  - [3. Activation function](#3-activation-function)
    - [3.1 Choose activation function](#31-choose-activation-function)
    - [3.2 Why we need activation function](#32-why-we-need-activation-function)
  - [4. Multiclass classification](#4-multiclass-classification)
    - [4.1 Example](#41-example)
    - [4.2 Softmax](#42-softmax)
  - [5. Multi-label classification](#5-multi-label-classification)
  - [6. 高级优化方法](#6-高级优化方法)

---

## 1. Train a neural Network in Tensorflow

![Train a neural Network in Tensorflow](images/2024-10-31-15-41-00.png)

---

## 2. Model training steps

![Model training steps](images/2024-10-31-15-53-14.png)

### 2.1 Create the model

![Create the model](images/2024-10-31-15-58-00.png)

### 2.2 Loss and cost functions

![Loss and cost functions](images/2024-10-31-16-05-12.png)

### 2.3 Gradient descent

![Gradient descent](images/2024-10-31-16-08-59.png)

---

## 3. Activation function

### 3.1 Choose activation function

二分类问题使用sigmoid，回归模型选择Linear，ReLU，取决于y

output layer

![output layer](images/2024-11-09-23-21-34.png)

Hidden Layer

更多选择ReLU，ReLU计算更快，其次只有一边是平坦的，梯度下降时更快

![Hidden Layer](images/2024-11-09-23-23-54.png)

![Choose activation function](images/2024-11-09-23-25-59.png)

### 3.2 Why we need activation function

![why we need activation function](images/2024-11-09-23-32-26.png)

---

## 4. Multiclass classification

### 4.1 Example

![Example](images/2024-11-10-10-26-01.png)

### 4.2 Softmax  

![Softmax](images/2024-11-10-10-34-39.png)

cost functions

![cost function](images/2024-11-10-10-40-47.png)

Neural Network with Softmax output

![Neural Network with Softmax output](images/2024-11-10-10-45-37.png)

more accurate

![more accurate](images/2024-11-10-11-18-22.png)

---

## 5. Multi-label classification

可以用3个神经网络，或者1个神经网络

![Multi-label classification](images/2024-11-10-15-16-27.png)

---

## 6. 高级优化方法

Adam algorithm intuition

![Adam algorithm intuition](images/2024-11-10-15-20-35.png)

对每个参数使用不同的学习率

![对每个参数使用不同的学习率](images/2024-11-10-15-21-38.png)

increase or reduce

![increase or reduce](images/2024-11-10-15-23-14.png)

---
