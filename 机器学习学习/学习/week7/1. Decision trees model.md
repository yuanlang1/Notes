# Decision trees model

- [Decision trees model](#decision-trees-model)
  - [1. Decision Tree](#1-decision-tree)
  - [2. Decision Tree Learning](#2-decision-tree-learning)
    - [2.1 Decision problem](#21-decision-problem)
    - [2.2 Measuring purity](#22-measuring-purity)
  - [3. Choosing a split](#3-choosing-a-split)
  - [4. 流程](#4-流程)
  - [5. 回归树](#5-回归树)
  - [6. 使用多颗决策树](#6-使用多颗决策树)
  - [7. XGboost](#7-xgboost)
  - [8. When to use decision trees](#8-when-to-use-decision-trees)

---

## 1. Decision Tree

![Decision Tree](images/2024-11-12-10-06-28.png)

---

## 2. Decision Tree Learning

### 2.1 Decision problem

- Decision 1: How to choose what feature to split on at each node?
  - Maximize purity or minimize impurity
- Decision 2: when do you stop splitting?
  - ![when do you stop splitting?](images/2024-11-12-10-21-41.png)
  
### 2.2 Measuring purity

![Measuring purity](images/2024-11-12-10-28-23.png)

entropy function

![Measuring purity](images/2024-11-12-10-30-48.png)

---

## 3. Choosing a split

计算信息增益

![计算信息增益](images/2024-11-12-10-45-01.png)

![计算信息增益](images/2024-11-12-10-47-09.png)

---

## 4. 流程

![流程](images/2024-11-12-10-50-14.png)

递归实现

![流程](images/2024-11-12-10-55-40.png)

splitting on a continuous variable，尝试不同的阈值

![splitting on a continuous variable](images/2024-11-12-11-10-25.png)

---

## 5. 回归树

回归树的信息增益，计算方差作为权重，找方差减少最大的作为分裂节点

![回归树](images/2024-11-12-11-20-52.png)

---

## 6. 使用多颗决策树

建立多颗决策树，分别进行预测，对结果进行投票

![多颗决策树](images/2024-11-12-11-26-44.png)

---

## 7. XGboost

用于增强决策树

![用于增强决策树](images/2024-11-12-15-04-00.png)

XGBoost(eXtreme Gradient Boosting)

![XGBoost(eXtreme Gradient Boosting)](images/2024-11-12-15-05-20.png)

---

## 8. When to use decision trees

决策树适用于结构化数据，例如表格之类的，不适合图像等非结构化数据。

Decision Trees vs Neural Networks

![When to use decision trees](images/2024-11-12-15-11-54.png)

---
